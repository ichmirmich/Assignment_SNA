---
title: "troll wip1"
author: "Johannes Kopf"
date: "24 November 2018"
output: pdf_document
---

"If you publish using the data, please credit NBC News, link to this page, and let us know. Send questions and projects to ben.popken@nbcuni.com or @bpopken." NBC article

https://golovchenko.github.io/tutorials/snatrolls.html


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(igraph)
library(dplyr)
library(readr)
library(knitr)
```

```{r, include=F}
## loading the data and setting working directory
tweets <- read.csv("C:/Google Drive/Universität/Master/Kopenhagen/Social Network Analysis/Troll-Data/tweets.csv", stringsAsFactors = F, sep = ",")
```

```{r, inlcude=F}
## loading the 538 twitter data for comparison of account types
tweets1 <- read.csv("Raw Data/IRAhandle_tweets_1.csv", stringsAsFactors = F, sep = ",")
tweets2 <- read.csv("Raw Data/IRAhandle_tweets_2.csv", stringsAsFactors = F, sep = ",")
tweets3 <- read.csv("Raw Data/IRAhandle_tweets_3.csv", stringsAsFactors = F, sep = ",")
tweets4 <- read.csv("Raw Data/IRAhandle_tweets_4.csv", stringsAsFactors = F, sep = ",")
tweets5 <- read.csv("Raw Data/IRAhandle_tweets_5.csv", stringsAsFactors = F, sep = ",")
tweets6 <- read.csv("Raw Data/IRAhandle_tweets_6.csv", stringsAsFactors = F, sep = ",")
tweets7 <- read.csv("Raw Data/IRAhandle_tweets_7.csv", stringsAsFactors = F, sep = ",")
tweets8 <- read.csv("Raw Data/IRAhandle_tweets_8.csv", stringsAsFactors = F, sep = ",")
tweets9 <- read.csv("Raw Data/IRAhandle_tweets_9.csv", stringsAsFactors = F, sep = ",")
tweets10 <- read.csv("Raw Data/IRAhandle_tweets_10.csv", stringsAsFactors = F, sep = ",")
tweets11 <- read.csv("Raw Data/IRAhandle_tweets_11.csv", stringsAsFactors = F, sep = ",")
tweets12 <- read.csv("Raw Data/IRAhandle_tweets_12.csv", stringsAsFactors = F, sep = ",")
tweets13 <- read.csv("Raw Data/IRAhandle_tweets_13.csv", stringsAsFactors = F, sep = ",")
tweets_538 <- rbind(tweets1, tweets2, tweets3 , tweets4, tweets5, tweets6, tweets7, tweets8, tweets9,tweets10, tweets11, tweets12, tweets13)
```

```{r, include=F}
## number of unique handles in the NBC dataset, who (re-)tweet themselves
unique_tweeting_handles_in_NBC_dataset <- select(tweets, user_key) %>% unique()
## 453 (all of them trolls, following NBC article)
## ego-centered network of those 453 troll accounts
```


```{r, include=F}
## number of handles for which we have accounty types (right/left/...)

## extracting handle variable and account_type variabe and removing duplicates
myvars <- c("author", "account_type") 
account_type <- tweets_538[myvars] %>% unique()
## 2843

## making variable name identical
tweets <- tweets %>% rename(handle = user_key)
account_type <- account_type %>% rename(handle = author)

## adding account_type variable to the NBC dataset
account_type$handle <- tolower(account_type$handle)
tweets <- left_join(tweets, account_type)

## for how many tweeting troll handles is an account type available?
handles <- select(tweets, handle, account_type) %>% unique()
length(na.omit(handles$account_type)) ## 443
443/453
## roughly 98% available
```

```{r}
length(unique(tweets$user_id))
## 393
length(unique(tweets$handle))
## 453

## Es gibt 393 unique user IDs und 453 unique handles. Da macht es Sinn, zu versuchen die unterschiedlichen handles mit selber ID im datensatz zusammen zulegen, oder?

unique_users <- select(tweets, user_id, handle)
unique_users <- unique(unique_users)

#summary(tweets_unique_users$user_id)


length(na.omit(tweets$user_id))
## 195,386
203451 - 195386
## 8,065 user ids are missing

summary(unique_users$user_id)
## they are NAs!!!!!!!!!!!!!!!!!!!!!!

summary(tweets$created_str)
```

```{r, include=F}
## Code by Yevgeniy Golovchenko: https://golovchenko.github.io/tutorials/snatrolls.html
## selecting only the retweets
rts <- grep("^rt @[a-z0-9_]{1,15}", tolower(tweets$text), perl=T, value=T)

## number of retweets in the dataset
rts.as.df <- as.data.frame(rts) %>% rename(text = rts)
## 147,428
147428/203451
## ~72% of all tweets in the NBC dataset are retweets

## extracting handle names for the senders (those who retweet)
rt.sender <- tolower(as.character(tweets$handle[grep("^rt @[a-z0-9_]{1,15}", tolower(tweets$text), perl=T)]))

## how many unique retweet senders?
rt.sender.df <- as.data.frame(rt.sender) %>% unique() %>% rename(handle = rt.sender)
## 333 trolls retweeted 147,428 times

147428/333
## average of ~443 per troll (but distribution is probably highly skewed)

453-333
## 120 trolls only tweeted and did not retweet (but could be retweeted)

## extracting handle names for the recievers (those who are being retweeted)
rt.receiver<- tolower(regmatches(rts, regexpr("@(?U).*:", rts)))
rt.receiver <- (gsub(":", "", rt.receiver)) ## removing ":"
rt.receiver <- (gsub("@", "", rt.receiver)) ## removing "@"

## how many unique retweet receivers?
rt.receiver.df <- as.data.frame(rt.receiver) %>% unique() %>% rename(handle = rt.receiver)
## 36,707 unique handles are being retweeted
## calculating the share of trolls later

## Registering empty entries as missing
## i think that the following code is not needed, because there are no empty entries
## rt.sender[rt.sender==""] <- "<NA>"
## rt.receiver[rt.receiver==""] <- "<NA>"
```

```{r, include=F}
## storing reciever and sender handle names in one dataframe and removing duplicates
handles_all <- unique(as.data.frame(c(rt.sender, rt.receiver))) %>% rename(handle = "c(rt.sender, rt.receiver)")
## There are 36,889 unique handles in the retweet dataset
## There are senders (only trolls) and receivers (trolls and non-trolls) in the unique set of handles.

36889-36707 ## 182
## Number of unique handles increases by 182 when adding the senders. Therefore, there are 182 trolls in the data, who sent but did not receive retweets
182/333
## ~55% of trolls, who are senders, were not themself retweeted (are no receivers)

333-182
## There are 151 trolls who retweeted others and were themselves retweeted. They are the only nodes in our data that are both senders and reveivers (that we know of -> unknown edges).
151/333
## ~45% of trolls who are senders are also receivers

36707-151
## 36,556 handles receive a retweet, but do not send a retweet
## Next, the share of trolls in these new handles will be calculated.
```

```{r, include=F}
## importing handle names from the official list release in congress
trolls_official <-  read.csv("http://golovchenko.github.io/data/trollhandles.txt", stringsAsFactors = F)
trolls_official$handle <- tolower(trolls_official$handle)
## 2752 trolls are defined by the list of the US congress
## https://democrats-intelligence.house.gov/uploadedfiles/exhibit_b.pdf

## all troll handles in NBC dataset
handles <- tweets %>% select(handle) %>% unique() 
## 453

## merging the complete list of official troll handle names with the handle names in NBC data
handles_trolls <- rbind(trolls_official, handles) %>% unique() 
## 2752
## all of the tweeting handles in the NBC data are officially trolls
```

```{r, include=F}
## how many trolls are in the overall dataset, either as senders or receivers?
trolls_official$troll <- "troll" ## assigning all of these users a troll

## matching trolls with the complete set of handle names in the retweet network
nodes <- right_join(trolls_official, handles_all)
length(na.omit(nodes$troll)) 
## there are 389 trolls in the retweet network
389-333
## There are 56 trolls who are retweeted, but do not tweet themselves

## share of troll nodes in the data
length(na.omit(nodes$troll))/length(nodes$troll)
## ~1.1% of nodes are trolls
## 100% of nodes with an outdegree > 0 are trolls
## ~0.6% of nodes with an indegree > 0 are trolls

receiver_troll_share <- right_join(trolls_official, rt.receiver.df)
## 207 trolls are retweeted
length(na.omit(receiver_troll_share$troll))/length(receiver_troll_share$troll)
## ~0.0056

nodes <- replace(nodes, is.na(nodes), "non-troll") ## now we have a variable indicating wether a user is a troll

nodes <- left_join(nodes, account_type)
#nodes <- right_join(nodes, unique_users)

length(na.omit(nodes$account_type))
389-333
## 394 handles are regarded as trolls by the 538 dataset
```

```{r, include=F}
## loading the additional user data to extract followers count
followers <- read.csv("C:/Google Drive/Universität/Master/Kopenhagen/Social Network Analysis/Troll-Data/users.csv", stringsAsFactors = F, sep = ",")

followers <- select(followers, screen_name, followers_count)
followers$screen_name <- tolower(followers$screen_name)
followers <- followers %>% rename(handle = screen_name)
length(na.omit(followers$followers_count))
## 453 - 383
## there is a followers_count available for 383 trolls (not available for 70)

tweets <- left_join(tweets, followers)
nodes <- left_join(nodes, followers)

## turning all NAs for account_type into "regular" for regular user (=non-troll)
nodes$account_type <- replace(nodes$account_type, is.na(nodes$account_type), "regular")
```

```{r, echo=F}
length(nodes$account_type[nodes$account_type == "regular"])
## 36495 handles are regular users according to the 538 dataset

length(nodes$troll[nodes$troll == "non-troll"])
## 36500

## the lists disagree
## 16, 171, 177, 257, 264, 271, 283, 293, 297, 309

unique(nodes$account_type)
## 13 types of accounts

m <- length(nodes$account_type[nodes$account_type == "Right"])
## 101 trolls are right

a <- length(nodes$account_type[nodes$account_type == "Left"])
## 110 trolls are left

b <- length(nodes$account_type[nodes$account_type == "Hashtager"])
## 61 trolls are hashtagers

c <- length(nodes$account_type[nodes$account_type == "news"])
## 4 trolls

d <- length(nodes$account_type[nodes$account_type == "Russian"])
## 77 trolls

e <- length(nodes$account_type[nodes$account_type == "German"])
## 23 trolls

f <- length(nodes$account_type[nodes$account_type == "French"])
## 5 trolls

n <- length(nodes$account_type[nodes$account_type == "Spanish"])
## 1 troll

h <- length(nodes$account_type[nodes$account_type == "?"])
## 1 troll

i <- length(nodes$account_type[nodes$account_type == "local"])
## 7 trolls

j <- length(nodes$account_type[nodes$account_type == "Ebola "])
## 2 trolls

k <- length(nodes$account_type[nodes$account_type == "Koch"])
## 1 troll

l <- length(nodes$account_type[nodes$account_type == "ZAPOROSHIA"])
## 1 troll

a+b+c+d+e+f+h+i+j+k+l+m+n
## 394
```

```{r, include=F}
## Creating a data frame from the sender-receiver objects
rts.df <- data.frame(rt.sender, rt.receiver)
## creating the retweetnetwork based on the sender-receiver df and the node attributes: troll/nontroll, account_type, followers_count
rts.g <- graph.data.frame(rts.df, directed=T, vertices = nodes)
## removing self-ties and multiple edges between users
g <- simplify(rts.g, remove.loops = T, remove.multiple = T)
```

```{r, inlcude=F}
## exporting the rts.g graph object as a graphml file 
write.graph(g, file="troll_network.graphml", format="graphml")
```

questions: 
*other dataset than in synposis
*community detection algorithm cross-validation feasible
*including other tables/plots expectations?






#################################################
#################################################
From here on, other plots etc. are prepared

```{r, include=F}
## creating a data frame with weighted and unweighted degree centrality for each profile
df <- data.frame(name = V(g)$name,
                 troll = V(g)$troll,
                 account_type = V(g)$account_type,
                 followers = V(g)$followers_count,
                 indegree=degree(g,mode='in'),
                 indegree_weighted = degree(rts.g, mode ="in"),
                 outdegree = degree(g, mode= 'out'),
                 outdegree_weighted = degree(rts.g, mode = "out"))
```

```{r, inlude=F}
## ranking users by indegree
rank.indegree <- df %>% select(name, troll, account_type, indegree,
                          indegree_weighted) %>% arrange(-indegree)
## ranking users b weigted indegree n users * n retweets
rank.indegree.w <- df %>% select(name, troll, account_type, indegree,
                          indegree_weighted) %>% arrange(-indegree_weighted)
```

```{r, echo=F}
kable(rank.indegree[1:10,], caption = "Top 10 profiles ranked by indegree")
```

```{r, echo=F}
kable(rank.indegree.w[1:10,], caption = "Top 10 profiles ranked by weighted indegree")
```

```{r, echo=F}
## subsetting the graph by removing non-trolls
## selecting nodes to exclude
exclude <- V(rts.g)[troll == "non-troll"]
## excluding the nodes
g.troll <- delete.vertices(rts.g, exclude)

## vizualizing the graph
par(bg ="grey10")
plot.igraph(g.troll,layout= layout.fruchterman.reingold(g.troll),
            edge.color="grey",
            edge.curved= .2, vertex.label = NA, vertex.frame.color="#ffffff",
            vertex.size = 2, edge.size = 0.01, edge.arrow.size = 0.01)
```

```{r, echo=F}
## decomposing the graph into components and returning the largest one
comp <- decompose(g.troll, mode = c("weak"), max.comps = 1,
                  min.vertices = 1)
## plotting the graph
par(bg ="grey10")
plot.igraph(comp[[1]],layout= layout.fruchterman.reingold(comp[[1]]),
            edge.color="grey",
            edge.curved= .2, vertex.label = NA, vertex.frame.color="#ffffff",
            vertex.size = 4, edge.size = 0.005, edge.arrow.size = 0.01)
```


