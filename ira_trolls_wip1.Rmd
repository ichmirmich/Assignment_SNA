---
title: "troll wip1"
author: "Johannes Kopf"
date: "24 November 2018"
output: pdf_document
---

"If you publish using the data, please credit NBC News, link to this page, and let us know. Send questions and projects to ben.popken@nbcuni.com or @bpopken." NBC article

https://golovchenko.github.io/tutorials/snatrolls.html


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(igraph)
library(dplyr)
library(readr)
library(knitr)
library(ggplot2)
```

```{r, include=F}
## loading the NBC News dataset and setting working directory
tweets <- read.csv("Raw Data/tweets.csv", stringsAsFactors = F, sep = ",")
```

```{r, inlcude=F}
## loading the 538 twitter dataset for comparison of account types
tweets1 <- read.csv("Raw Data/IRAhandle_tweets_1.csv", stringsAsFactors = F, sep = ",")
tweets2 <- read.csv("Raw Data/IRAhandle_tweets_2.csv", stringsAsFactors = F, sep = ",")
tweets3 <- read.csv("Raw Data/IRAhandle_tweets_3.csv", stringsAsFactors = F, sep = ",")
tweets4 <- read.csv("Raw Data/IRAhandle_tweets_4.csv", stringsAsFactors = F, sep = ",")
tweets5 <- read.csv("Raw Data/IRAhandle_tweets_5.csv", stringsAsFactors = F, sep = ",")
tweets6 <- read.csv("Raw Data/IRAhandle_tweets_6.csv", stringsAsFactors = F, sep = ",")
tweets7 <- read.csv("Raw Data/IRAhandle_tweets_7.csv", stringsAsFactors = F, sep = ",")
tweets8 <- read.csv("Raw Data/IRAhandle_tweets_8.csv", stringsAsFactors = F, sep = ",")
tweets9 <- read.csv("Raw Data/IRAhandle_tweets_9.csv", stringsAsFactors = F, sep = ",")
tweets10 <- read.csv("Raw Data/IRAhandle_tweets_10.csv", stringsAsFactors = F, sep = ",")
tweets11 <- read.csv("Raw Data/IRAhandle_tweets_11.csv", stringsAsFactors = F, sep = ",")
tweets12 <- read.csv("Raw Data/IRAhandle_tweets_12.csv", stringsAsFactors = F, sep = ",")
tweets13 <- read.csv("Raw Data/IRAhandle_tweets_13.csv", stringsAsFactors = F, sep = ",")
tweets_538 <- rbind(tweets1, tweets2, tweets3 , tweets4, tweets5, tweets6, tweets7, tweets8, tweets9,tweets10, tweets11, tweets12, tweets13) ## merging into one dataset
rm(tweets1, tweets2, tweets3 , tweets4, tweets5, tweets6, tweets7, tweets8, tweets9,tweets10, tweets11, tweets12, tweets13) ## removing for better oversight in environment
```

```{r, include=F}
## number of handles for which we have accounty types (right/left/...)
## extracting handle variable and account_type variabe and removing duplicates
myvars <- c("author", "account_category") 
account_category <- tweets_538[myvars] %>% unique()
## 2843

unique(tweets_538$account_category)

## making variable name identical
tweets <- tweets %>% rename(handle = user_key)
account_category <- account_category %>% rename(handle = author)

## adding account_type variable to the NBC dataset
account_category$handle <- tolower(account_category$handle)
tweets <- left_join(tweets, account_category)

## for how many tweeting troll handles is an account type available?
handles <- select(tweets, handle, account_category) %>% unique()
length(na.omit(handles$account_category)) / length(handles$handle)
## roughly for 98% available
```

```{r, include=F}
## Code by Yevgeniy Golovchenko: https://golovchenko.github.io/tutorials/snatrolls.html

## selecting only the retweets
rts <- grep("^rt @[a-z0-9_]{1,15}", tolower(tweets$text), perl=T, value=T)

## number of retweets in the dataset
rts.as.df <- as.data.frame(rts) %>% rename(text = rts)
## 147,428
length(rts.as.df$text) / length(tweets$handle)
## ~72% of all tweets in the NBC dataset are retweets

## extracting handle names for the senders (those who retweet)
rt.sender <- tolower(as.character(tweets$handle[grep("^rt @[a-z0-9_]{1,15}", tolower(tweets$text), perl = T)]))

## how many unique retweet senders?
rt.sender.df <- as.data.frame(rt.sender) %>% unique() %>% rename(handle = rt.sender)
length(rt.sender.df$handle)
## 333 trolls retweeted 147,428 times

## how many trolls have not retweeted anyone and therefore are not in the network
length(unique(tweets$handle)) - length(rt.sender.df$handle)
## 120 trolls only tweeted and did not retweet (but could be retweeted)

## extracting handle names for the recievers (those who are being retweeted)
rt.receiver <- tolower(regmatches(rts, regexpr("@(?U).*:", rts)))
rt.receiver <- (gsub(":", "", rt.receiver)) ## removing ":"
rt.receiver <- (gsub("@", "", rt.receiver)) ## removing "@"

## how many unique retweet receivers?
rt.receiver.df <- as.data.frame(rt.receiver) %>% unique() %>% rename(handle = rt.receiver)
legth(rt.receiver.df$handle)
## 36,707 unique handles are being retweeted
## calculating the share of trolls later

## Registering empty entries as missing
## i think that the following code is not needed, because there are no empty entries
## rt.sender[rt.sender==""] <- "<NA>"
## rt.receiver[rt.receiver==""] <- "<NA>"
```

```{r, include=F}
## storing reciever and sender handle names in one dataframe and removing duplicates
handles_all <- unique(as.data.frame(c(rt.sender, rt.receiver))) %>% rename(handle = "c(rt.sender, rt.receiver)")
## There are 36,889 unique handles in the retweet dataset
## There are senders (only trolls) and receivers (trolls and non-trolls) in the unique set of handles.

36889 - length(rt.receiver.df$handle)
## Number of unique handles increases by 182 when adding the senders. Therefore, there are 182 trolls in the data, who sent but did not receive retweets

182 / length(rt.sender.df$handle)
## ~55% of trolls, who are senders, were not themself retweeted (are no receivers)

333 - 182
## There are 151 trolls who retweeted others and were themselves retweeted. They are the only nodes in our data that are both senders and reveivers (that we know of).

151 / length(rt.sender.df$handle)
## ~45% of trolls who are senders are also receivers

36707 - 151
## 36,556 handles receive a retweet, but do not send a retweet
## Next, the share of trolls in these new handles will be calculated.
```

```{r, include=F}
## importing handle names from the official list release in congress
trolls_official <-  read.csv("http://golovchenko.github.io/data/trollhandles.txt", stringsAsFactors = F)

trolls_official$handle <- tolower(trolls_official$handle)

## importing newer handle names
trolls_official_new <- read.delim("Raw Data/ira_handles.txt", sep="")

trolls_official_new$handle <- tolower(trolls_official_new$handle)
## 3841

trolls <- rbind(trolls_official, trolls_official_new) %>% unique()
## together 3848 (+7 from old list)

## all troll handles in NBC dataset
handles <- tweets %>% select(handle) %>% unique() 
## 453

## merging the complete list of official troll handle names with the handle names in NBC data
handles_trolls <- rbind(trolls_official, trolls_official_new, handles) %>% unique() 

## 3848
## all of the tweeting handles in the NBC data are officially trolls
```

```{r, include=F}
###Merging the older NBC list of trolls, with the newer Linvill/Warren; adding "troll" and "non-troll" labels as attributes###

## how many trolls are in the overall dataset, either as senders or receivers?
trolls_official$troll <- "troll" ## assigning all of these users a troll
trolls$troll <- "troll"

## matching trolls with the complete set of handle names in the retweet network
nodes <- right_join(trolls, handles_all)
length(na.omit(nodes$troll)) 
## there are 404 trolls in the retweet network

404-333
## There are 71 trolls who are retweeted, but do not tweet themselves

nodes <- replace(nodes, is.na(nodes), "non-troll") ## now we have a variable indicating wether a user is a troll

nodes <- left_join(nodes, account_category)
#nodes <- right_join(nodes, unique_users)

troll_nodes <- filter(nodes, nodes$troll == "troll")
length(na.omit(troll_nodes$account_category))
## 379 handles are regarded as trolls by the 538 dataset
## 389 handles are regarded as trolls by the NBC dataset
## 10 'trolls' don't have a category

394/404
## 98% category available

length(nodes$troll[nodes$troll=="non-troll"])
##36485 non-trolls in the dataset
```

```{r, include=F}
###Adding follower count as node attribute###

## loading the additional user data to extract followers count
followers <- read.csv("Raw Data/users.csv", stringsAsFactors = F, sep = ",")

followers <- select(followers, screen_name, followers_count)
followers$screen_name <- tolower(followers$screen_name)
followers <- followers %>% rename(handle = screen_name)
length(na.omit(followers$followers_count))
## there is a followers_count available for 383 trolls (not available for 70)

tweets <- left_join(tweets, followers)
nodes <- left_join(nodes, followers)

## turning all NAs for account_type into "Unknown" for regular user (=non-troll)
troll_nodes$account_category <- replace(troll_nodes$account_category, is.na(troll_nodes$account_category), "Unknown")
troll_nodes <- left_join(troll_nodes, followers)

nodes <- left_join(nodes, troll_nodes, by ="handle")

nodes$account_category.y <- replace(nodes$account_category.y, is.na(nodes$account_category.y), "Non-Troll")
nodes$troll.y <- replace(nodes$troll.y, is.na(nodes$troll.y), "non-troll")

nodes <- select(nodes, handle, troll.y, account_category.y, followers_count.y) %>% rename(account_category = account_category.y)
nodes <- nodes %>% rename(troll = troll.y)

```

```{r, include = F}
###Creating the graph###

## Creating a data frame from the sender-receiver objects
rts.df <- data.frame(rt.sender, rt.receiver)

## creating the retweetnetwork based on the sender-receiver df and the node attributes: troll/nontroll, account_type, followers_count
rts.g <- graph.data.frame(rts.df, directed = T, vertices = nodes)

## removing self-ties and multiple edges between users
g <- simplify(rts.g, remove.loops = T, remove.multiple = T)

## creating an undirected graph object
g.undir <- as.undirected(g, mode = "collapse")
```

```{r, include = F}
## subsetting the graph by removing non-trolls

## removing loops and multiples
rts.g <- simplify(rts.g, remove.multiple = T, remove.loops = T)

## selecting nodes to exclude
exclude <- V(rts.g)[account_category == "Non-Troll"]
## excluding the nodes
g.troll <- delete.vertices(rts.g, exclude)

## creating an undirected subgraph
g.troll.undir <- as.undirected(g.troll, mode = "collapse")
```

```{r, include=F}
## GRAPH DENSITY

## to do: calculate without only retweeted trolls!

## whole graph, directed and undirected
graph.density(g, loops = F)
## 0.00006
graph.density(g.undir, loops = F)
## 0.00012

## subgraph of trolls, directed and undirected
graph.density(g.troll, loops = F)
## 0.0076
graph.density(g.troll.undir, loops = F)
## 0.0145

## for subgraphs of account type

#### right troll
## right directed
exclude <- V(g.troll)[account_category != "RightTroll"]
g.troll.right <- delete.vertices(g.troll, exclude)
graph.density(g.troll.right, loops = F)
## 0.0591

## right undirected
exclude <- V(g.troll.undir)[account_category != "RightTroll"]
g.troll.right.undir <- delete.vertices(g.troll.undir, exclude)
graph.density(g.troll.right.undir, loops = F)
## 0.1119

#### left troll
## left directed
exclude <- V(g.troll)[account_category != "LeftTroll"]
g.troll.left <- delete.vertices(g.troll, exclude)
graph.density(g.troll.left, loops = F)
## 0.0082

## left undirected
exclude <- V(g.troll.undir)[account_category != "LeftTroll"]
g.troll.left.undir <- delete.vertices(g.troll.undir, exclude)
graph.density(g.troll.left.undir, loops = F)
## 0.0158
```


```{r, include = F}
## computing graph coreness
V(g)$Kcore = graph.coreness(g)
## computing degree
V(g)$degree <- degree(g)
```

```{r}
## Community detection

# running infomap community detection
infomap <- cluster_infomap(g, nb.trials = 10,
                          modularity = T)

# running modularity optimization community detection
modularity <- cluster_louvain(g.undir)

##attatching the communities to the data frames
V(g)$modularity <- modularity$membership
V(g)$infomap <- infomap$membership

df.community <- data.frame(handle = V(g)$name, infomap = V(g)$infomap, modularity = V(g)$modularity)

nodes <- left_join(nodes, df.community, by = "handle")
## re-creating the retweetnetwork based on the sender-receiver df and the node attributes: troll/nontroll, account_type, followers_count, infomap, modularity
rts.g <- graph.data.frame(rts.df, directed = T, vertices = nodes)

## removing self-ties and multiple edges between users
rts.g <- simplify(rts.g, remove.loops = T, remove.multiple = F)
g <- simplify(rts.g, remove.loops = T, remove.multiple = T)

## creating an undirected graph object
g.undir <- as.undirected(g, mode = "collapse")

```

```{r, include=F}
## COMMUNITY DETECTION ANALYIS

troll_nodes <- left_join(troll_nodes, df.community, by = "handle") ## appending community variables

## PLOT

## reordering of the bars
positions <- c("LeftTroll", "NonEnglish", "RightTroll", "HashtagGamer", "NewsFeed", "Unknown", "Fearmonger")

## plot
png(filename = "figure1.png", width = 700, height = 480)
ggplot(troll_nodes, aes(x=account_category)) +
  geom_bar(aes(fill = as.character(modularity)), show.legend = F 
           ) + scale_x_discrete(limits = positions) + 
  ggtitle("Distribution of Communities among Account Categories by Linvill/Warren (2018)") +
    ylab("Number of Trolls") +
  xlab("")
dev.off()

```

```{r}
## ACCOUNT CATEGORIES & COMMUNITIES IN NUMBERS 

## Right community (Linvill/Warren)
## gives proportion of communities in account categories
right_troll_communities <- filter(nodes, account_category == "RightTroll")
comms <- unique(right_troll_communities$modularity)

for (com in comms){
  print(com)
  print(length(right_troll_communities$modularity[right_troll_communities$modularity==com])/length(right_troll_communities$modularity))
}

## Left
left_troll_communities <- filter(nodes, account_category == "LeftTroll")
comms <- unique(left_troll_communities$modularity)

for (com in comms){
  print(com)
  print(length(left_troll_communities$modularity[left_troll_communities$modularity==com])/length(left_troll_communities$modularity))
}

## Hastager
hashtag_troll_communities <- filter(nodes, account_category == "HashtagGamer")
comms <- unique(hashtag_troll_communities$modularity)
communities <- unique(troll_nodes$modularity)

for (com in comms){
  print(com)
  print(length(hashtag_troll_communities$modularity[hashtag_troll_communities$modularity==com])/length(hashtag_troll_communities$modularity))
}

for (com in comms){
  print(length(hashtag_troll_communities$modularity[hashtag_troll_communities$modularity==com])/length(hashtag_troll_communities$modularity))
}

## Non-English
nonenglish_troll_communities <- filter(nodes, account_category == "NonEnglish")
comms <- unique(nonenglish_troll_communities$modularity)

for (com in comms){
  print(length(nonenglish_troll_communities$modularity[nonenglish_troll_communities$modularity==com])/length(nonenglish_troll_communities$modularity))
}

## picking the biggest communities of each account category as the representative(s) for this group

## creating new categories from modularity + Linvill/Warren

troll_nodes$com <- troll_nodes$modularity

## numbers are taken from the investigation of biggest communities within account categories that was carried out above
## all small communities are not examined any further and therefore merged into "Other"
troll_nodes$com[troll_nodes$com == 4] <- "Left"
troll_nodes$com[troll_nodes$com == 10] <- "Right"
troll_nodes$com[troll_nodes$com == 8] <- "Right"
troll_nodes$com[troll_nodes$com == 6] <- "Hashtager"
troll_nodes$com[troll_nodes$com != "Left" & troll_nodes$com != "Right" & troll_nodes$com != "Hashtager"] <- "Other"

## PLOT 2 WITH NEW CATEGORIES

positions2 <- c("Right", "Left", "Hashtager", "Other")

ggplot(troll_nodes, aes(x=com)) +
  geom_bar(aes(fill = as.character(modularity)), show.legend=F 
           ) + scale_x_discrete(limits = positions2) + 
  ggtitle("Distribution of Communities within Account Categories by Linvill/Warren (2018)") +
  xlab("Sythesis of Qualitative and Modularity Algorithm Communities") +
  ylab("Number of Trolls") +
  labs(caption = "Note: Color reflects distinct communities using modularity community detection following ...")

## plot 3 with new categoires

ggplot(troll_nodes, aes(x=com)) +
  geom_bar(aes(fill = as.character(account_category)), show.legend=T 
           ) + scale_x_discrete(limits = positions2) + 
  ggtitle("Distribution of Account Categories among Newly Created Communities") +
  xlab("Newly Created Categories") +
  ylab("Number of Trolls") +
  labs(caption = "Note: Color reflects account categories by Linvill/Warren (2018).")  + theme(legend.title=element_blank())

## appending coms to nodes
com.df <- select(troll_nodes, handle, com)
nodes <- left_join(nodes, com.df)
nodes$com[is.na(nodes$com)] <- "Non-Troll"


## recreating the retweetnetwork to include new communities
rts.g <- graph.data.frame(rts.df, directed=T, vertices = nodes)

## removing self-ties and multiple edges between users
g <- simplify(rts.g, remove.loops = T, remove.multiple = T)

## creating an undirected graph object
g.undir <- as.undirected(g, mode = "collapse")

## selecting nodes to exclude
exclude <- V(rts.g)[com == "Non-Troll"]
## excluding the nodes
g.troll <- delete.vertices(rts.g, exclude)

## creating an undirected subgraph
g.troll.undir <- as.undirected(g.troll, mode = "collapse")
```

```{r}
## new right community
right_troll_communities <- filter(nodes, com == "Right")
comms <- unique(right_troll_communities$modularity)

for (com in comms){
  print(com)
  print(length(right_troll_communities$modularity[right_troll_communities$modularity==com])/length(right_troll_communities$modularity))
}

## new "other" community
other_troll_communities <- filter(nodes, com == "Other")
comms <- unique(other_troll_communities$modularity)

for (com in comms){
  print(com)
  print(length(other_troll_communities$modularity[other_troll_communities$modularity==com])/length(other_troll_communities$modularity))
}
```

```{r}
a <- c("grummz", "clickhole")
neighbors(g, "grummz", mode="in")

degree()

adjacent_vertices(g, a, mode="in")
degree(g, b, mode="in")
#a <- as.character(V(g)[name == v])

for (v in V(g)[name]){
  neighbors(g, v, mode = "in")
}
```


```{r, include=F}
## GRAPH DENSITY

## to do: calculate without only retweeted trolls!

## whole graph, directed and undirected
graph.density(g, loops=F)
## 0.00006
graph.density(g.undir, loops=F)
## 0.00012

## subgraph of trolls, directed and undirected
graph.density(g.troll, loops=F)
## 0.029
graph.density(g.troll.undir, loops=F)
## 0.03

## for subgraphs of account type

#### right troll
## right directed
exclude <- V(g.troll)[com != "Right"]
g.troll.right <- delete.vertices(g.troll, exclude)
graph.density(g.troll.right, loops=F)
## 0.131

## right undirected
exclude <- V(g.troll.undir)[com != "Right"]
g.troll.right.undir <- delete.vertices(g.troll.undir, exclude)
graph.density(g.troll.right.undir, loops=F)
## 0.145

#### left troll
## left directed
exclude <- V(g.troll)[com != "Left"]
g.troll.left <- delete.vertices(g.troll, exclude)
graph.density(g.troll.left, loops=F)
## 0.021

## left undirected
exclude <- V(g.troll.undir)[com != "Left"]
g.troll.left.undir <- delete.vertices(g.troll.undir, exclude)
graph.density(g.troll.left.undir, loops=F)
## 0.038

#### Hashtager
## hashtager directed
exclude <- V(g.troll)[com != "Hashtager"]
g.troll.hash <- delete.vertices(g.troll, exclude)
graph.density(g.troll.hash, loops=F)
## 0.564

## hashtager undirected
exclude <- V(g.troll.undir)[com != "Hashtager"]
g.troll.hash.undir <- delete.vertices(g.troll.undir, exclude)
graph.density(g.troll.hash.undir, loops=F)
## 0.466 LOWER????
```


```{r, include = F}
## computing graph coreness
V(g)$Kcore = graph.coreness(g)
core.df <- graph.coreness(g) %>% as.data.frame()
## computing degree
V(g)$degree <- degree(g)
```



```{r, inlcude=F}
## exporting the rts.g graph object as a graphml file 
write.graph(g, file="troll_network.graphml", format="graphml")
```


weiterer code aus Yevgeniys script rauskopiert

```{r}
## Vizualising communites based on infomap algorithm
plot(g.troll,
     vertex.size = 2,
     vertex.label.color = "black",
     vertex.label.cex = .1
     )

## Vizualising communities based on modularity optimization algorithm
plot(g,
     vertex.size = 20,
     vertex.label.color = "black",
     vertex.label.cex = 1,
     vertex.color = modularity$membership)

## Vizualising communites based on Girvan and Newman's degree-based community detection
plot(g,
     vertex.size = 20,
     vertex.label.color = "black",
     vertex.label.cex = 1,
     vertex.color = deg_com$membership)



### example:
plot(g,
     vertex.size = 20,
     vertex.label.color = "black",
     vertex.label.cex = 1,
     vertex.color = V(g)$yourvariablename)

```



```{r, include=F}
## creating summary statistics
library(stargazer)

## using numbers from calculations that can be seen in the chapter on data description
User <- c("Troll", "Non-Troll", "Total")
N <- c("404", "36,485", "36,889")
Senders <- c("333", "0", "333")
Receivers <- c("222", "36,485", "36,707")

table1 <- cbind(User, N, Senders, Receivers)

stargazer(table1, summary=F, align=T, title="User Statistics")
```

```{r, include=F}
## creating summary stats for trolls only

## first, vectors are created, which are later used as variables in the table

## Rownames
Category <- c("Right", "Left", "Hashtag Gamer", "Non-English", "Newsfeed", "Fearmonger", "Unknown", "Total")

## Number of Trolls
N <- c(length(troll_nodes$account_category[troll_nodes$account_category=="RightTroll"]), length(troll_nodes$account_category[troll_nodes$account_category=="LeftTroll"]), length(troll_nodes$account_category[troll_nodes$account_category=="HashtagGamer"]), length(troll_nodes$account_category[troll_nodes$account_category=="NonEnglish"]), length(troll_nodes$account_category[troll_nodes$account_category=="NewsFeed"]), length(troll_nodes$account_category[troll_nodes$account_category=="Fearmonger"]), length(troll_nodes$account_category[troll_nodes$account_category=="Unknown"]), "404")

## Sender Count
rt.sender.df <- left_join(rt.sender.df, account_category)
rt.sender.df$account_category <- replace(rt.sender.df$account_category, is.na(rt.sender.df$account_category), "Unknown")

Senders <- c(length(rt.sender.df$account_category[rt.sender.df$account_category=="RightTroll"]), length(rt.sender.df$account_category[rt.sender.df$account_category=="LeftTroll"]),              length(rt.sender.df$account_category[rt.sender.df$account_category=="HashtagGamer"]),
length(rt.sender.df$account_category[rt.sender.df$account_category=="NonEnglish"]),  length(rt.sender.df$account_category[rt.sender.df$account_category=="NewsFeed"]), length(rt.sender.df$account_category[rt.sender.df$account_category=="Fearmonger"]), length(rt.sender.df$account_category[rt.sender.df$account_category=="Unknown"]), "333")                    

rt.sender.df$sender <- "Sender"
troll_nodes <- left_join(troll_nodes, rt.sender.df)

## Receiver Count
rt.receiver.df$receiver <- "Receiver"
troll_nodes <- left_join(troll_nodes, rt.receiver.df)
receiver_count <- filter(troll_nodes, troll_nodes$receiver=="Receiver")

Receivers <- c(length(receiver_count$account_category[receiver_count$account_category=="RightTroll"]), length(receiver_count$account_category[receiver_count$account_category=="LeftTroll"]),              length(receiver_count$account_category[receiver_count$account_category=="HashtagGamer"]),
length(receiver_count$account_category[receiver_count$account_category=="NonEnglish"]),  length(receiver_count$account_category[receiver_count$account_category=="NewsFeed"]), length(receiver_count$account_category[receiver_count$account_category=="Fearmonger"]), length(receiver_count$account_category[receiver_count$account_category=="Unknown"]), "222")                                                          
## Followers

## creating sub-dataframes for each troll group
right_trolls <- filter(troll_nodes, troll_nodes$account_category=="RightTroll")
left_trolls <- filter(troll_nodes, troll_nodes$account_category=="LeftTroll")
hashtager <- filter(troll_nodes, troll_nodes$account_category=="HashtagGamer")
nonenglish <- filter(troll_nodes, troll_nodes$account_category=="NonEnglish")
newsfeed <- filter(troll_nodes, troll_nodes$account_category=="NewsFeed")
fearmonger <- filter(troll_nodes, troll_nodes$account_category=="Fearmonger")
unknown <- filter(troll_nodes, troll_nodes$account_category=="Unknown")

## calculating the rounded average while omitting NAs
Average_Followers <- c(round(mean(na.omit(right_trolls$followers_count), digits=0)), round(mean(na.omit(left_trolls$followers_count)), digits=0), round(mean(na.omit(hashtager$followers_count)), digits=0), round(mean(na.omit(nonenglish$followers_count)), digits=0), round(mean(na.omit(newsfeed$followers_count)), digits=0), 0, round(mean(na.omit(unknown$followers_count)), digits=0), 4476)

table2 <- cbind(Category, N, Senders, Receivers, Average_Followers)

stargazer(table2, summary=F, align=T, title="Troll Statistics")
```



#################################################
#################################################
From here on, other plots etc. are prepared
```{r}
## understanding user ids, WILL BE TIDIED UP
length(unique(tweets$user_id))
## 393
length(unique(tweets$handle))
## 453

## Es gibt 393 unique user IDs und 453 unique handles. Da macht es Sinn, zu versuchen die unterschiedlichen handles mit selber ID im datensatz zusammen zulegen, oder?

unique_users <- select(tweets, user_id, handle)
unique_users <- unique(unique_users)

#summary(tweets_unique_users$user_id)


length(na.omit(tweets$user_id))
## 195,386
203451 - 195386
## 8,065 user ids are missing

summary(unique_users$user_id)
## they are NAs!!!!!!!!!!!!!!!!!!!!!!

summary(tweets$created_str)
```


```{r}
plot(g,
     main="K Cores",
     vertex.size = 20,
     vertex.label = V(g)$Kcore,
     vertex.label.color = "black",
     vertex.label.cex = 1,
     vertex.color = "white")
```


```{r, include=F}
## creating a data frame with weighted and unweighted degree centrality for each profile
df <- data.frame(name = V(g)$name,
                 troll = V(g)$troll,
                 account_category = V(g)$account_category,
                 indegree=degree(g, mode = 'in'),
                 indegree_weighted = degree(rts.g, mode = "in"),
                 outdegree = degree(g, mode= 'out'),
                 outdegree_weighted = degree(rts.g, mode = "out"))
```

```{r, inlude=F}
## ranking users by indegree
rank.indegree <- df %>% select(name, troll, account_category, indegree,
                          indegree_weighted) %>% arrange(-indegree)
## ranking users b weigted indegree n users * n retweets
rank.indegree.w <- df %>% select(name, troll, account_category, indegree,
                          indegree_weighted) %>% arrange(-indegree_weighted)
```

```{r, echo=F}
kable(rank.indegree[1:10,], caption = "Top 10 profiles ranked by indegree")
```

```{r, echo=F}
kable(rank.indegree.w[1:10,], caption = "Top 10 profiles ranked by weighted indegree")
```

```{r}
## ranking users by outdegree
rank.outdegree <- df %>% select(name, troll, account_category, outdegree,
                          outdegree_weighted) %>% arrange(-outdegree)
## ranking users b weigted indegree n users * n retweets
rank.outdegree.w <- df %>% select(name, troll, account_category, outdegree,
                          outdegree_weighted) %>% arrange(-outdegree_weighted)
```

```{r}
kable(rank.outdegree[1:10,], caption = "Top 10 profiles ranked by outdegree")
```


```{r, echo=F}


## vizualizing the graph
par(bg ="grey10")
plot.igraph(g.troll,layout= layout.fruchterman.reingold(g.troll),
            edge.color="grey",
            edge.curved= .2, vertex.label = NA, vertex.frame.color="#ffffff",
            vertex.size = 2, edge.size = 0.01, edge.arrow.size = 0.01)
```

```{r, echo=F}
## decomposing the graph into components and returning the largest one
comp <- decompose(g.troll, mode = c("weak"), max.comps = 1,
                  min.vertices = 1)
## plotting the graph
par(bg ="grey10")
plot.igraph(comp[[1]],layout= layout.fruchterman.reingold(comp[[1]]),
            edge.color="grey",
            edge.curved= .2, vertex.label = NA, vertex.frame.color="#ffffff",
            vertex.size = 4, edge.size = 0.005, edge.arrow.size = 0.01)
```


