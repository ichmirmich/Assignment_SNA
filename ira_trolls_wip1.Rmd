---
title: "troll wip1"
author: "Johannes Kopf"
date: "24 November 2018"
output: pdf_document
---

"If you publish using the data, please credit NBC News, link to this page, and let us know. Send questions and projects to ben.popken@nbcuni.com or @bpopken." NBC article

https://golovchenko.github.io/tutorials/snatrolls.html


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(igraph)
library(dplyr)
library(readr)
library(knitr)
```

```{r, include=F}
## loading the data and setting working directory
tweets <- read.csv("C:/Google Drive/Universität/Master/Kopenhagen/Social Network Analysis/Troll-Data/tweets.csv", stringsAsFactors = F, sep = ",")
```

```{r, inlcude=F}
## loading the 538 twitter data for comparison of account types
tweets1 <- read.csv("Raw Data/IRAhandle_tweets_1.csv", stringsAsFactors = F, sep = ",")
tweets2 <- read.csv("Raw Data/IRAhandle_tweets_2.csv", stringsAsFactors = F, sep = ",")
tweets3 <- read.csv("Raw Data/IRAhandle_tweets_3.csv", stringsAsFactors = F, sep = ",")
tweets4 <- read.csv("Raw Data/IRAhandle_tweets_4.csv", stringsAsFactors = F, sep = ",")
tweets5 <- read.csv("Raw Data/IRAhandle_tweets_5.csv", stringsAsFactors = F, sep = ",")
tweets6 <- read.csv("Raw Data/IRAhandle_tweets_6.csv", stringsAsFactors = F, sep = ",")
tweets7 <- read.csv("Raw Data/IRAhandle_tweets_7.csv", stringsAsFactors = F, sep = ",")
tweets8 <- read.csv("Raw Data/IRAhandle_tweets_8.csv", stringsAsFactors = F, sep = ",")
tweets9 <- read.csv("Raw Data/IRAhandle_tweets_9.csv", stringsAsFactors = F, sep = ",")
tweets10 <- read.csv("Raw Data/IRAhandle_tweets_10.csv", stringsAsFactors = F, sep = ",")
tweets11 <- read.csv("Raw Data/IRAhandle_tweets_11.csv", stringsAsFactors = F, sep = ",")
tweets12 <- read.csv("Raw Data/IRAhandle_tweets_12.csv", stringsAsFactors = F, sep = ",")
tweets13 <- read.csv("Raw Data/IRAhandle_tweets_13.csv", stringsAsFactors = F, sep = ",")
tweets_538 <- rbind(tweets1, tweets2, tweets3 , tweets4, tweets5, tweets6, tweets7, tweets8, tweets9,tweets10, tweets11, tweets12, tweets13) ## merging into one dataset
rm(tweets1, tweets2, tweets3 , tweets4, tweets5, tweets6, tweets7, tweets8, tweets9,tweets10, tweets11, tweets12, tweets13) ## removing for better oversight in environment
```

```{r, include=F}
## number of handles for which we have accounty types (right/left/...)
## extracting handle variable and account_type variabe and removing duplicates
myvars <- c("author", "account_category") 
account_category <- tweets_538[myvars] %>% unique()
## 2843

unique(tweets_538$account_category)

## making variable name identical
tweets <- tweets %>% rename(handle = user_key)
account_category <- account_category %>% rename(handle = author)

## adding account_type variable to the NBC dataset
account_category$handle <- tolower(account_category$handle)
tweets <- left_join(tweets, account_category)

## for how many tweeting troll handles is an account type available?
handles <- select(tweets, handle, account_category) %>% unique()
length(na.omit(handles$account_category)) ## 443
443/453
## around 98% available
```

```{r}
## understanding user ids, will be tidied up later
length(unique(tweets$user_id))
## 393
length(unique(tweets$handle))
## 453

## Es gibt 393 unique user IDs und 453 unique handles. Da macht es Sinn, zu versuchen die unterschiedlichen handles mit selber ID im datensatz zusammen zulegen, oder?

unique_users <- select(tweets, user_id, handle)
unique_users <- unique(unique_users)

#summary(tweets_unique_users$user_id)


length(na.omit(tweets$user_id))
## 195,386
203451 - 195386
## 8,065 user ids are missing

summary(unique_users$user_id)
## they are NAs!!!!!!!!!!!!!!!!!!!!!!

summary(tweets$created_str)
```

```{r, include=F}
## Code by Yevgeniy Golovchenko: https://golovchenko.github.io/tutorials/snatrolls.html
## selecting only the retweets
rts <- grep("^rt @[a-z0-9_]{1,15}", tolower(tweets$text), perl=T, value=T)

## number of retweets in the dataset
rts.as.df <- as.data.frame(rts) %>% rename(text = rts)
## 147,428
147428/203451
## ~72% of all tweets in the NBC dataset are retweets

## extracting handle names for the senders (those who retweet)
rt.sender <- tolower(as.character(tweets$handle[grep("^rt @[a-z0-9_]{1,15}", tolower(tweets$text), perl=T)]))

## how many unique retweet senders?
rt.sender.df <- as.data.frame(rt.sender) %>% unique() %>% rename(handle = rt.sender)
## 333 trolls retweeted 147,428 times

147428/333
## average of ~443 per troll (but distribution is probably highly skewed)

453-333
## 120 trolls only tweeted and did not retweet (but could be retweeted)

## extracting handle names for the recievers (those who are being retweeted)
rt.receiver<- tolower(regmatches(rts, regexpr("@(?U).*:", rts)))
rt.receiver <- (gsub(":", "", rt.receiver)) ## removing ":"
rt.receiver <- (gsub("@", "", rt.receiver)) ## removing "@"

## how many unique retweet receivers?
rt.receiver.df <- as.data.frame(rt.receiver) %>% unique() %>% rename(handle = rt.receiver)
## 36,707 unique handles are being retweeted
## calculating the share of trolls later

## Registering empty entries as missing
## i think that the following code is not needed, because there are no empty entries
## rt.sender[rt.sender==""] <- "<NA>"
## rt.receiver[rt.receiver==""] <- "<NA>"
```

```{r, include=F}
## storing reciever and sender handle names in one dataframe and removing duplicates
handles_all <- unique(as.data.frame(c(rt.sender, rt.receiver))) %>% rename(handle = "c(rt.sender, rt.receiver)")
## There are 36,889 unique handles in the retweet dataset
## There are senders (only trolls) and receivers (trolls and non-trolls) in the unique set of handles.

36889-36707 ## 182
## Number of unique handles increases by 182 when adding the senders. Therefore, there are 182 trolls in the data, who sent but did not receive retweets
182/333
## ~55% of trolls, who are senders, were not themself retweeted (are no receivers)

333-182
## There are 151 trolls who retweeted others and were themselves retweeted. They are the only nodes in our data that are both senders and reveivers (that we know of -> unknown edges).
151/333
## ~45% of trolls who are senders are also receivers

36707-151
## 36,556 handles receive a retweet, but do not send a retweet
## Next, the share of trolls in these new handles will be calculated.
```

```{r, include=F}
## importing handle names from the official list release in congress
trolls_official <-  read.csv("http://golovchenko.github.io/data/trollhandles.txt", stringsAsFactors = F)

trolls_official$handle <- tolower(trolls_official$handle)

## importing handle newer handle names
trolls_official_new <- read.delim("C:/Google Drive/Universität/Master/Kopenhagen/Social Network Analysis/538/Github for 538/Assignment_SNA/Raw Data/ira_handles.txt", sep="")

trolls_official_new$handle <- tolower(trolls_official_new$handle)
## 3841

trolls <- rbind(trolls_official, trolls_official_new) %>% unique()
## together 3848 (+7 from old list)

## all troll handles in NBC dataset
handles <- tweets %>% select(handle) %>% unique() 
## 453

## merging the complete list of official troll handle names with the handle names in NBC data
handles_trolls <- rbind(trolls_official, trolls_official_new, handles) %>% unique() 

## 3848
## all of the tweeting handles in the NBC data are officially trolls
```

```{r, include=F}
## how many trolls are in the overall dataset, either as senders or receivers?
trolls_official$troll <- "troll" ## assigning all of these users a troll
trolls$troll <- "troll"

## matching trolls with the complete set of handle names in the retweet network
nodes <- right_join(trolls, handles_all)
length(na.omit(nodes$troll)) 
## there are 404 trolls in the retweet network
404-333
## There are 71 trolls who are retweeted, but do not tweet themselves

#receiver_troll_share <- right_join(trolls, rt.receiver.df)
## 207 trolls are retweeted
#length(na.omit(receiver_troll_share$troll))
## ~0.0056

nodes <- replace(nodes, is.na(nodes), "non-troll") ## now we have a variable indicating wether a user is a troll

nodes <- left_join(nodes, account_category)
#nodes <- right_join(nodes, unique_users)

troll_nodes <- filter(nodes, nodes$troll == "troll")
length(na.omit(troll_nodes$account_category))
## 379 handles are regarded as trolls by the 538 dataset
## 389 handles are regarded as trolls by the NBC dataset
## 10 'trolls' don't have a category
394/404
## 98% category available
length(nodes$troll[nodes$troll=="non-troll"])
```

```{r, include=F}
## loading the additional user data to extract followers count
followers <- read.csv("C:/Google Drive/Universität/Master/Kopenhagen/Social Network Analysis/Troll-Data/users.csv", stringsAsFactors = F, sep = ",")

followers <- select(followers, screen_name, followers_count)
followers$screen_name <- tolower(followers$screen_name)
followers <- followers %>% rename(handle = screen_name)
length(na.omit(followers$followers_count))
## 453 - 383
## there is a followers_count available for 383 trolls (not available for 70)

tweets <- left_join(tweets, followers)
nodes <- left_join(nodes, followers)

## turning all NAs for account_type into "regular" for regular user (=non-troll)
troll_nodes$account_category <- replace(troll_nodes$account_category, is.na(troll_nodes$account_category), "Unknown")
troll_nodes <- left_join(troll_nodes, followers)

nodes <- left_join(nodes, troll_nodes, by ="handle")

nodes$account_category.y <- replace(nodes$account_category.y, is.na(nodes$account_category.y), "Non-Troll")
nodes$troll.y <- replace(nodes$troll.y, is.na(nodes$troll.y), "non-troll")

nodes <- select(nodes, handle, troll.y, account_category.y, followers_count) %>% rename(account_category = account_category.y)
nodes <- nodes %>% rename(troll = troll.y)

```

```{r, include=F}
## Creating a data frame from the sender-receiver objects
rts.df <- data.frame(rt.sender, rt.receiver)

## creating the retweetnetwork based on the sender-receiver df and the node attributes: troll/nontroll, account_type, followers_count
rts.g <- graph.data.frame(rts.df, directed=T, vertices = nodes)

## removing self-ties and multiple edges between users
g <- simplify(rts.g, remove.loops = T, remove.multiple = T)

## creating an undirected graph object
rts.g.undirected <- graph.data.frame(rts.df, directed=F, vertices = nodes)
g_undirected <- simplify(rts.g.undirected, remove.loops = T, remove.multiple = T)
```

```{r, include=F}
### computing graph coreness
V(g)$Kcore = graph.coreness(g)
#computing degree
V(g)$degree <- degree(g)
```

```{r, inlcude=F}
## exporting the rts.g graph object as a graphml file 
write.graph(g, file="troll_network.graphml", format="graphml")
```



################################################


```{r}
## communities, from session 12 on communities

# running infomap community detection
infomap<- cluster_infomap(g, nb.trials = 10,
                          modularity = F)

# running modularity optimization community detection
modularity <- cluster_louvain(g)

## running Girvan and Newman's degree-based community detection
deg_com <- cluster_edge_betweenness(g)
```

weiterer code aus Yevgeniys script rauskopiert

```{r}
## Vizualising communites based on infomap algorithm
plot(g,
     vertex.size = 20,
     vertex.label.color = "black",
     vertex.label.cex = 1,
     vertex.color = infomap$membership)

## Vizualising communities based on modularity optimization algorithm
plot(g,
     vertex.size = 20,
     vertex.label.color = "black",
     vertex.label.cex = 1,
     vertex.color = modularity$membership)

## Vizualising communites based on Girvan and Newman's degree-based community detection
plot(g,
     vertex.size = 20,
     vertex.label.color = "black",
     vertex.label.cex = 1,
     vertex.color = deg_com$membership)

### what if you want to store the output from the algoritm above in the graph object before exporting? Use the code bellow
V(g)$community <- deg_com$membership

df.community <- data.frame(name = V(g)$name, community = V(g)$community)
head(df.community)
## this can be appended to our nodes dataframe (with right.join/left.join)

### example:
plot(g,
     vertex.size = 20,
     vertex.label.color = "black",
     vertex.label.cex = 1,
     vertex.color = V(g)$yourvariablename)

```



```{r, include=F}
## creating summary statistics
library(stargazer)

## using numbers from calculations that can be seen in the chapter on data description
User <- c("Troll", "Non-Troll", "Total")
N <- c("404", "36,485", "36,889")
Senders <- c("333", "0", "333")
Receivers <- c("222", "36,485", "36,707")

table1 <- cbind(User, N, Senders, Receivers)

stargazer(table1, summary=F, align=T, title="User Statistics")
```

```{r, include=F}
## creating summary stats for trolls only

## first, vectors are created, which are later used as variables in the table

## Rownames
Category <- c("Right", "Left", "Hashtag Gamer", "Non-English", "Newsfeed", "Fearmonger", "Unknown", "Total")

## Number of Trolls
N <- c(length(troll_nodes$account_category[troll_nodes$account_category=="RightTroll"]), length(troll_nodes$account_category[troll_nodes$account_category=="LeftTroll"]), length(troll_nodes$account_category[troll_nodes$account_category=="HashtagGamer"]), length(troll_nodes$account_category[troll_nodes$account_category=="NonEnglish"]), length(troll_nodes$account_category[troll_nodes$account_category=="NewsFeed"]), length(troll_nodes$account_category[troll_nodes$account_category=="Fearmonger"]), length(troll_nodes$account_category[troll_nodes$account_category=="Unknown"]), "404")

## Sender Count
rt.sender.df <- left_join(rt.sender.df, account_category)
rt.sender.df$account_category <- replace(rt.sender.df$account_category, is.na(rt.sender.df$account_category), "Unknown")

Senders <- c(length(rt.sender.df$account_category[rt.sender.df$account_category=="RightTroll"]), length(rt.sender.df$account_category[rt.sender.df$account_category=="LeftTroll"]),              length(rt.sender.df$account_category[rt.sender.df$account_category=="HashtagGamer"]),
length(rt.sender.df$account_category[rt.sender.df$account_category=="NonEnglish"]),  length(rt.sender.df$account_category[rt.sender.df$account_category=="NewsFeed"]), length(rt.sender.df$account_category[rt.sender.df$account_category=="Fearmonger"]), length(rt.sender.df$account_category[rt.sender.df$account_category=="Unknown"]), "333")                    

rt.sender.df$sender <- "Sender"
troll_nodes <- left_join(troll_nodes, rt.sender.df)

## Receiver Count
rt.receiver.df$receiver <- "Receiver"
troll_nodes <- left_join(troll_nodes, rt.receiver.df)
receiver_count <- filter(troll_nodes, troll_nodes$receiver=="Receiver")

Receivers <- c(length(receiver_count$account_category[receiver_count$account_category=="RightTroll"]), length(receiver_count$account_category[receiver_count$account_category=="LeftTroll"]),              length(receiver_count$account_category[receiver_count$account_category=="HashtagGamer"]),
length(receiver_count$account_category[receiver_count$account_category=="NonEnglish"]),  length(receiver_count$account_category[receiver_count$account_category=="NewsFeed"]), length(receiver_count$account_category[receiver_count$account_category=="Fearmonger"]), length(receiver_count$account_category[receiver_count$account_category=="Unknown"]), "222")                                                          
## Followers

## creating sub-dataframes for each troll group
right_trolls <- filter(troll_nodes, troll_nodes$account_category=="RightTroll")
left_trolls <- filter(troll_nodes, troll_nodes$account_category=="LeftTroll")
hashtager <- filter(troll_nodes, troll_nodes$account_category=="HashtagGamer")
nonenglish <- filter(troll_nodes, troll_nodes$account_category=="NonEnglish")
newsfeed <- filter(troll_nodes, troll_nodes$account_category=="NewsFeed")
fearmonger <- filter(troll_nodes, troll_nodes$account_category=="Fearmonger")
unknown <- filter(troll_nodes, troll_nodes$account_category=="Unknown")

## calculating the rounded average while omitting NAs
Average_Followers <- c(round(mean(na.omit(right_trolls$followers_count), digits=0)), round(mean(na.omit(left_trolls$followers_count)), digits=0), round(mean(na.omit(hashtager$followers_count)), digits=0), round(mean(na.omit(nonenglish$followers_count)), digits=0), round(mean(na.omit(newsfeed$followers_count)), digits=0), 0, round(mean(na.omit(unknown$followers_count)), digits=0), 4476)

table2 <- cbind(Category, N, Senders, Receivers, Average_Followers)

stargazer(table2, summary=F, align=T, title="Troll Statistics")
```



#################################################
#################################################
From here on, other plots etc. are prepared

```{r}
## breaks session
plot(g,
     main="K Cores",
     vertex.size = 20,
     vertex.label = V(g)$Kcore,
     vertex.label.color = "black",
     vertex.label.cex = 1,
     vertex.color = "white")
```


```{r, include=F}
## creating a data frame with weighted and unweighted degree centrality for each profile
df <- data.frame(name = V(g)$name,
                 troll = V(g)$troll,
                 account_category = V(g)$account_category,
                 followers = V(g)$followers_count,
                 indegree=degree(g,mode='in'),
                 indegree_weighted = degree(rts.g, mode ="in"),
                 outdegree = degree(g, mode= 'out'),
                 outdegree_weighted = degree(rts.g, mode = "out"))
```

```{r, inlude=F}
## ranking users by indegree
rank.indegree <- df %>% select(name, troll, account_category, indegree,
                          indegree_weighted) %>% arrange(-indegree)
## ranking users b weigted indegree n users * n retweets
rank.indegree.w <- df %>% select(name, troll, account_category, indegree,
                          indegree_weighted) %>% arrange(-indegree_weighted)
```

```{r, echo=F}
kable(rank.indegree[1:10,], caption = "Top 10 profiles ranked by indegree")
```

```{r, echo=F}
kable(rank.indegree.w[1:10,], caption = "Top 10 profiles ranked by weighted indegree")
```

```{r, echo=F}
## subsetting the graph by removing non-trolls
## selecting nodes to exclude
exclude <- V(rts.g)[troll == "non-troll"]
## excluding the nodes
g.troll <- delete.vertices(rts.g, exclude)

## vizualizing the graph
par(bg ="grey10")
plot.igraph(g.troll,layout= layout.fruchterman.reingold(g.troll),
            edge.color="grey",
            edge.curved= .2, vertex.label = NA, vertex.frame.color="#ffffff",
            vertex.size = 2, edge.size = 0.01, edge.arrow.size = 0.01)
```

```{r, echo=F}
## decomposing the graph into components and returning the largest one
comp <- decompose(g.troll, mode = c("weak"), max.comps = 1,
                  min.vertices = 1)
## plotting the graph
par(bg ="grey10")
plot.igraph(comp[[1]],layout= layout.fruchterman.reingold(comp[[1]]),
            edge.color="grey",
            edge.curved= .2, vertex.label = NA, vertex.frame.color="#ffffff",
            vertex.size = 4, edge.size = 0.005, edge.arrow.size = 0.01)
```


